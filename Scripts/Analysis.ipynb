{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8279b6c8",
   "metadata": {},
   "source": [
    "# ADF test for stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e6d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox, het_arch\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from arch import arch_model\n",
    "\n",
    "# Download S&P 500 historical data (ticker: ^GSPC)\n",
    "data = yf.download('^GSPC', start='2000-01-01', end='2020-12-31')\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Calculate log returns from 'Adj Close' prices\n",
    "data['LogReturn'] = np.log(data['Close'] / data['Close'].shift(1))\n",
    "\n",
    "# Drop NaNs resulting from the shift\n",
    "log_returns = data['LogReturn'].dropna()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(log_returns)\n",
    "plt.title('Log Returns of S&P 500 (2000-2020)')  # Add title\n",
    "plt.xlabel('Date')  # Add x-axis label\n",
    "plt.ylabel('Log Return')  # Add y-axis label\n",
    "plt.savefig('log_returns_plot.png')\n",
    "\n",
    "adf_result = adfuller(log_returns)\n",
    "\n",
    "print('ADF Statistic: %f' % adf_result[0])\n",
    "print('p-value: %f' % adf_result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in adf_result[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "if adf_result[1] <= 0.05:\n",
    "    print(\"Reject the null hypothesis: Time series is stationary\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: Time series is non-stationary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bd027e",
   "metadata": {},
   "source": [
    "# Existence of Volatility Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. ARMA Model Fitting ---\n",
    "# Choose ARMA(1,0,1) as example; adjust (p,d,q) as needed\n",
    "arma_order = (1, 0, 1)\n",
    "arma_model = ARIMA(log_returns, order=arma_order).fit()\n",
    "print(\"\\nARMA Model Summary:\")\n",
    "print(arma_model.summary())\n",
    "\n",
    "# Extract ARMA parameters for table\n",
    "arma_params = arma_model.params\n",
    "arma_bse = arma_model.bse\n",
    "arma_tvalues = arma_model.tvalues\n",
    "arma_pvalues = arma_model.pvalues\n",
    "\n",
    "arma_table = pd.DataFrame({\n",
    "    \"Parameter\": arma_params.index,\n",
    "    \"Estimate\": arma_params.values,\n",
    "    \"Std. Error\": arma_bse.values,\n",
    "    \"t-value\": arma_tvalues.values,\n",
    "    \"p-value\": arma_pvalues.values\n",
    "})\n",
    "\n",
    "# --- 2. Residual Diagnostics ---\n",
    "# Ljung-Box test for residual autocorrelation\n",
    "ljung_box = acorr_ljungbox(arma_model.resid, lags=[10], return_df=True)\n",
    "print(\"\\nLjung-Box test for residual autocorrelation:\")\n",
    "print(ljung_box)\n",
    "\n",
    "# ARCH-LM test for ARCH effects\n",
    "arch_test_stat, arch_test_pvalue, _, _ = het_arch(arma_model.resid)\n",
    "print(f\"\\nARCH-LM Test Statistic: {arch_test_stat:.4f}, p-value: {arch_test_pvalue:.4f}\")\n",
    "\n",
    "arch_table = pd.DataFrame({\n",
    "    \"Test Statistic\": [arch_test_stat],\n",
    "    \"p-value\": [arch_test_pvalue]\n",
    "})\n",
    "\n",
    "# --- 3. GARCH(1,1) Model Fitting ---\n",
    "# Fit GARCH(1,1) with zero mean (assuming ARMA captured mean)\n",
    "garch_model = arch_model(log_returns, vol='Garch', p=1, q=1, mean='Zero', dist='normal')\n",
    "garch_fit = garch_model.fit(update_freq=5, disp='off')\n",
    "print(\"\\nGARCH(1,1) Model Summary:\")\n",
    "print(garch_fit.summary())\n",
    "\n",
    "# Extract GARCH parameters for table\n",
    "garch_params = garch_fit.params\n",
    "garch_bse = garch_fit.std_err\n",
    "garch_tvalues = garch_fit.tvalues\n",
    "garch_pvalues = garch_fit.pvalues\n",
    "\n",
    "garch_table = pd.DataFrame({\n",
    "    \"Parameter\": garch_params.index,\n",
    "    \"Estimate\": garch_params.values,\n",
    "    \"Std. Error\": garch_bse.values,\n",
    "    \"t-value\": garch_tvalues.values,\n",
    "    \"p-value\": garch_pvalues.values\n",
    "})\n",
    "\n",
    "# --- 4. Plotting ---\n",
    "\n",
    "# a) Time Series Plot of Data\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(log_returns)\n",
    "plt.title('Time Series Plot of Stationary Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# b) ACF and PACF plots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
    "plot_acf(log_returns, lags=40, ax=ax[0])\n",
    "ax[0].set_title('ACF of Data')\n",
    "plot_pacf(log_returns, lags=40, ax=ax[1])\n",
    "ax[1].set_title('PACF of Data')\n",
    "plt.tight_layout()\n",
    "plt.savefig('acf_pacf_plot.png')\n",
    "\n",
    "# c) Residual and Squared Residual Plots from ARMA\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 6))\n",
    "ax[0].plot(arma_model.resid)\n",
    "ax[0].set_title('ARMA Model Residuals')\n",
    "ax[0].set_xlabel('Time')\n",
    "ax[0].set_ylabel('Residuals')\n",
    "\n",
    "ax[1].plot(arma_model.resid**2)\n",
    "ax[1].set_title('Squared Residuals from ARMA Model')\n",
    "ax[1].set_xlabel('Time')\n",
    "ax[1].set_ylabel('Squared Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('arma_resid_sqresid.png')\n",
    "\n",
    "# d) Conditional Volatility Plot from GARCH Model\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(garch_fit.conditional_volatility)\n",
    "plt.title('Conditional Volatility from GARCH(1,1) Model')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Volatility')\n",
    "plt.tight_layout()\n",
    "plt.savefig('garch_cond_vol.png')\n",
    "\n",
    "# e) Standardized Residuals and Squared Standardized Residuals from GARCH\n",
    "std_resid = garch_fit.std_resid\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 6))\n",
    "ax[0].plot(std_resid)\n",
    "ax[0].set_title('Standardized Residuals from GARCH Model')\n",
    "ax[0].set_xlabel('Time')\n",
    "ax[0].set_ylabel('Std Residuals')\n",
    "\n",
    "ax[1].plot(std_resid**2)\n",
    "ax[1].set_title('Squared Standardized Residuals from GARCH Model')\n",
    "ax[1].set_xlabel('Time')\n",
    "ax[1].set_ylabel('Squared Std Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('garch_std_resid.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb10c15",
   "metadata": {},
   "source": [
    "# Comparsion with Traditional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a0eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Parameters ---\n",
    "# Data Parameters\n",
    "TICKER_SPX = '^GSPC'\n",
    "TICKER_VIX = '^VIX'\n",
    "START_DATE = '2000-01-01'\n",
    "END_DATE = '2020-12-31'\n",
    "\n",
    "def fetch_data(ticker, start, end):\n",
    "    \"\"\"Fetches historical adjusted closing prices from Yahoo Finance.\"\"\"\n",
    "    try:\n",
    "        data = yf.download(ticker, start=start, end=end, progress=False)\n",
    "        if data is None or data.empty:\n",
    "            raise ValueError(f\"No data fetched for {ticker}\")\n",
    "        print(f\"Fetched {len(data)} rows for {ticker}\")\n",
    "        return data['Close']\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {type(e).__name__}, {e}\")\n",
    "        return None\n",
    "\n",
    "spx_price = fetch_data(TICKER_SPX, START_DATE, END_DATE)\n",
    "vix_price = fetch_data(TICKER_VIX, START_DATE, END_DATE)\n",
    "\n",
    "if spx_price is None or vix_price is None:\n",
    "    raise SystemExit(\"Failed to fetch necessary data. Exiting.\")\n",
    "\n",
    "df = pd.concat([spx_price, vix_price], axis=1)\n",
    "df.columns = ['SPX', 'VIX']\n",
    "df.ffill(inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "print(f\"Combined data shape after initial NaN handling: {df.shape}\")\n",
    "\n",
    "# Calculate Features and Targets\n",
    "df['SPX_LogRet'] = np.log(df['SPX'] / df['SPX'].shift(1))\n",
    "df['VIX_Level'] = df['VIX'] # Feature for LSTM\n",
    "\n",
    "# Preprocessing Parameters\n",
    "REALIZED_VOL_WINDOW = 5\n",
    "ANNUALIZATION_FACTOR = np.sqrt(252)\n",
    "\n",
    "# Calculate Realized Volatility (Target for LSTM and Evaluation)\n",
    "df['Realized_Vol'] = df['SPX_LogRet'].rolling(window=REALIZED_VOL_WINDOW).std() * ANNUALIZATION_FACTOR\n",
    "df['Realized_Vol_Target'] = df['Realized_Vol'].shift(-1) # Predict vol for t+1 using info up to t\n",
    "\n",
    "initial_rows = len(df)\n",
    "df.dropna(inplace=True)\n",
    "print(f\"Data shape after calculating returns/vol and dropping NaNs: {df.shape} (dropped {initial_rows - len(df)} rows)\")\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. Split the data\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, shuffle=False) \n",
    "\n",
    "# 2. Prepare train and test sets\n",
    "# Exogenous variables for train and test\n",
    "train_exog = train_data[['SPX_LogRet', 'VIX_Level']]\n",
    "test_exog = test_data[['SPX_LogRet', 'VIX_Level']]\n",
    "\n",
    "# Target variable for train and test\n",
    "train_target = train_data['Realized_Vol_Target']\n",
    "test_target = test_data['Realized_Vol_Target']\n",
    "\n",
    "# 3. Fit the model on the training data\n",
    "model = ARIMA(train_target, exog=train_exog, order=(1, 0, 1))\n",
    "model_fit = model.fit()\n",
    "\n",
    "# 4. Make predictions on the test data\n",
    "predictions = model_fit.predict(start=0, end=len(test_data)-1, exog=test_exog)\n",
    "\n",
    "# 5. Evaluate the model on the test data\n",
    "rmse = np.sqrt(mean_squared_error(test_target, predictions))\n",
    "print(f\"RMSE on Test Set: {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algotrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
