{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQqVGNwtS8Ne"
   },
   "outputs": [],
   "source": [
    "!pip install arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gN6o3oAvS8jK"
   },
   "outputs": [],
   "source": [
    "!pip install yfinance --upgrade --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599,
     "referenced_widgets": [
      "b515561205bc4a2cbf79703fc7f78e8c",
      "d886bf4ea00f49a7a21fc9803ba90105",
      "1eb7c8f655894d02903c2ff746513c4c",
      "08535dbdd9d64d1bab97599c0392567d",
      "b7502e8e9063469f87b7992a4adffa31",
      "7035e60f99bc42369329bca22af774c0",
      "74c2f36ea580455986ec43b3fe45b357",
      "ce98cd7d42cb49de9f0d27a9d9b5aef4",
      "974efcb13c9349b0a29b55bfde324dfc",
      "ca4408cfdcae4ee5960adc2e4e68b692",
      "64f4fd2a14f445beaccdc095f922ea1c"
     ]
    },
    "executionInfo": {
     "elapsed": 47428,
     "status": "error",
     "timestamp": 1746373367517,
     "user": {
      "displayName": "PakLok Chan",
      "userId": "09327407159625145417"
     },
     "user_tz": -480
    },
    "id": "6flQN901SpRn",
    "outputId": "52fb0404-2b44-4c31-e458-ec3e0fde0687"
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from arch import arch_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm # Use notebook version for better display\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress specific warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Maximum Likelihood optimization failed to converge.\") # GARCH convergence warnings\n",
    "\n",
    "# --- Constants (can be adjusted if needed) ---\n",
    "TICKER_SPX = '^GSPC'\n",
    "TICKER_VIX = '^VIX'\n",
    "START_DATE = '2000-01-01'\n",
    "END_DATE = '2020-12-31' # Use a consistent end date for fair comparison\n",
    "REALIZED_VOL_WINDOW = 5\n",
    "ANNUALIZATION_FACTOR = np.sqrt(252)\n",
    "TRAIN_TEST_SPLIT_RATIO = 0.8\n",
    "# Set a fixed seed for reproducibility (optional but recommended for tuning)\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    # Potentially add deterministic behavior settings\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# --- Data Fetching (Done once outside the loop) ---\n",
    "print(\"Fetching data...\")\n",
    "def fetch_data(ticker, start, end):\n",
    "    try:\n",
    "        data = yf.download(ticker, start=start, end=end, progress=False)\n",
    "        if data is None or data.empty:\n",
    "            raise ValueError(f\"No data fetched for {ticker}\")\n",
    "        print(f\"Fetched {len(data)} rows for {ticker}\")\n",
    "        return data['Close']\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {type(e).__name__}, {e}\")\n",
    "        return None\n",
    "\n",
    "spx_price = fetch_data(TICKER_SPX, START_DATE, END_DATE)\n",
    "vix_price = fetch_data(TICKER_VIX, START_DATE, END_DATE)\n",
    "\n",
    "if spx_price is None or vix_price is None:\n",
    "    raise SystemExit(\"Failed to fetch necessary data. Exiting.\")\n",
    "\n",
    "# Combine and preprocess initial features\n",
    "df_full = pd.concat([spx_price, vix_price], axis=1)\n",
    "df_full.columns = ['SPX', 'VIX']\n",
    "df_full.ffill(inplace=True)\n",
    "df_full.dropna(inplace=True) # Drop early NaNs if any\n",
    "\n",
    "df_full['SPX_LogRet'] = np.log(df_full['SPX'] / df_full['SPX'].shift(1))\n",
    "df_full['VIX_Level'] = df_full['VIX']\n",
    "df_full['Realized_Vol'] = df_full['SPX_LogRet'].rolling(window=REALIZED_VOL_WINDOW).std() * ANNUALIZATION_FACTOR\n",
    "df_full['Realized_Vol_Target'] = df_full['Realized_Vol'].shift(-1)\n",
    "\n",
    "df_full.dropna(inplace=True) # Drop NaNs created by calculations\n",
    "print(f\"Full preprocessed data shape: {df_full.shape}\")\n",
    "print(\"Data fetching and initial preprocessing complete.\")\n",
    "\n",
    "# --- Model Definitions (Copied from the original script) ---\n",
    "class LSTMVolModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):\n",
    "        super(LSTMVolModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # Apply dropout only if num_layers > 1\n",
    "        lstm_dropout = dropout if num_layers > 1 else 0\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
    "                            batch_first=True, dropout=lstm_dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0)) # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# --- Data Preparation Function (Copied) ---\n",
    "def create_lstm_sequences(data_logret, data_vix, target_data, seq_len):\n",
    "    xs, ys = [], []\n",
    "    data_logret_np = np.array(data_logret)\n",
    "    data_vix_np = np.array(data_vix)\n",
    "    target_data_np = np.array(target_data)\n",
    "\n",
    "    for i in range(len(data_logret_np) - seq_len):\n",
    "        # Ensure indices are valid\n",
    "        idx_end = i + seq_len\n",
    "        target_idx = idx_end # Target corresponds to the step after the sequence ends\n",
    "\n",
    "        # Check if target index is within bounds\n",
    "        if target_idx >= len(target_data_np):\n",
    "            continue # Skip if target index is out of bounds\n",
    "\n",
    "        x_logret = data_logret_np[i:idx_end]\n",
    "        x_vix = data_vix_np[i:idx_end]\n",
    "        x = np.stack((x_logret, x_vix), axis=1) # Features: LogRet, VIX\n",
    "        y = target_data_np[target_idx] # Target: Value at t+1 (index i + seq_len)\n",
    "\n",
    "        # Only append if the target is not NaN\n",
    "        if not np.isnan(y):\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "        # else:\n",
    "        #    print(f\"NaN target encountered at index {target_idx}, skipping sequence starting at {i}\")\n",
    "\n",
    "\n",
    "    # Handle case where no valid sequences are found\n",
    "    if not xs:\n",
    "         return np.array([]), np.array([]) # Return empty arrays\n",
    "\n",
    "\n",
    "    return np.array(xs), np.array(ys).reshape(-1, 1) # Ensure ys is 2D column vector\n",
    "\n",
    "\n",
    "# --- Training Function (Modified for less verbose output during tuning) ---\n",
    "def train_lstm(model, dataloader, epochs, learning_rate, device, model_name=\"LSTM\", verbose=False):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # Optional: Add a learning rate scheduler\n",
    "    # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    if verbose: print(f\"Training {model_name} on {device}...\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        # Simplified progress bar for tuning\n",
    "        pbar_batch = dataloader # No tqdm here to avoid excessive output\n",
    "        for inputs, targets in pbar_batch:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), targets.squeeze())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Optional: Step the scheduler\n",
    "        # scheduler.step()\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / len(dataloader)\n",
    "        if verbose and (epoch + 1) % 5 == 0: # Print every 5 epochs\n",
    "             print(f'Epoch [{epoch+1}/{epochs}], Average Loss: {avg_epoch_loss:.6f}')\n",
    "\n",
    "    if verbose: print(f\"{model_name} Training finished.\")\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# --- Core Experiment Function ---\n",
    "def run_experiment(params, df_full, device):\n",
    "    \"\"\"\n",
    "    Runs a single experiment with given hyperparameters.\n",
    "\n",
    "    Args:\n",
    "        params (dict): Dictionary of hyperparameters.\n",
    "        df_full (pd.DataFrame): Full preprocessed dataframe.\n",
    "        device (torch.device): Computation device ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing results (metrics) or None if an error occurs.\n",
    "    \"\"\"\n",
    "    print(f\"\\nRunning experiment with params: {params}\")\n",
    "\n",
    "    # Extract params\n",
    "    lstm_seq_len = params['LSTM_INPUT_SEQ_LEN']\n",
    "    lstm_hidden_size = params['LSTM_HIDDEN_SIZE']\n",
    "    lstm_num_layers = params['LSTM_NUM_LAYERS']\n",
    "    lstm_dropout = params['LSTM_DROPOUT']\n",
    "    lstm_epochs = params['LSTM_EPOCHS']\n",
    "    lstm_batch_size = params['LSTM_BATCH_SIZE']\n",
    "    lstm_lr = params['LSTM_LEARNING_RATE']\n",
    "    garch_p = params['GARCH_P']\n",
    "    garch_q = params['GARCH_Q']\n",
    "\n",
    "    # --- Train/Test Split ---\n",
    "    # Important: Split needs to be consistent *after* potential NaN removal due to seq_len\n",
    "    df = df_full.copy() # Work on a copy for each experiment\n",
    "    n_obs = len(df)\n",
    "    n_train = int(n_obs * TRAIN_TEST_SPLIT_RATIO)\n",
    "    # Ensure n_train leaves enough data for at least one test sequence\n",
    "    if n_train >= n_obs - lstm_seq_len:\n",
    "        n_train = n_obs - lstm_seq_len - 1 # Adjust if needed\n",
    "        if n_train <= 0:\n",
    "             print(\"Error: Not enough data for train/test split with current seq_len.\")\n",
    "             return None\n",
    "\n",
    "    train_df = df.iloc[:n_train].copy()\n",
    "    test_df = df.iloc[n_train:].copy()\n",
    "    test_indices = df.index[n_train:]\n",
    "\n",
    "    if len(train_df) < lstm_seq_len or len(test_df) < lstm_seq_len + 1:\n",
    "         print(f\"Warning: Insufficient data for train ({len(train_df)}) or test ({len(test_df)}) with seq_len {lstm_seq_len}. Skipping.\")\n",
    "         return None\n",
    "\n",
    "\n",
    "    # --- Feature Scaling ---\n",
    "    scaler_logret = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler_vix = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "    # Fit scalers ONLY on training data\n",
    "    # Handle potential constant columns in training data during scaling\n",
    "    try:\n",
    "        train_df['SPX_LogRet_Scaled'] = scaler_logret.fit_transform(train_df[['SPX_LogRet']])\n",
    "        train_df['VIX_Level_Scaled'] = scaler_vix.fit_transform(train_df[['VIX_Level']])\n",
    "\n",
    "        # Transform test data using the FITTED scalers\n",
    "        test_df['SPX_LogRet_Scaled'] = scaler_logret.transform(test_df[['SPX_LogRet']])\n",
    "        test_df['VIX_Level_Scaled'] = scaler_vix.transform(test_df[['VIX_Level']])\n",
    "    except ValueError as e:\n",
    "         print(f\"Error during scaling (potentially constant column in train split): {e}. Skipping.\")\n",
    "         return None\n",
    "\n",
    "\n",
    "    scaled_df = pd.concat([train_df, test_df])\n",
    "\n",
    "    # --- Initial Model Training ---\n",
    "    # 1. Train LSTM\n",
    "    # Target is the actual realized volatility (not scaled)\n",
    "    X_lstm_train_np, y_lstm_train_np = create_lstm_sequences(\n",
    "        train_df['SPX_LogRet_Scaled'],\n",
    "        train_df['VIX_Level_Scaled'],\n",
    "        train_df['Realized_Vol_Target'],\n",
    "        lstm_seq_len\n",
    "    )\n",
    "\n",
    "    # Check if sequence creation yielded data\n",
    "    if X_lstm_train_np.shape[0] == 0 or y_lstm_train_np.shape[0] == 0:\n",
    "        print(f\"Error: No LSTM training sequences created for seq_len {lstm_seq_len}. Maybe train_df too small? Skipping.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    X_lstm_train = torch.tensor(X_lstm_train_np, dtype=torch.float32)\n",
    "    y_lstm_train = torch.tensor(y_lstm_train_np, dtype=torch.float32) # Already has shape [N, 1] from function\n",
    "\n",
    "    lstm_dataset = TensorDataset(X_lstm_train, y_lstm_train)\n",
    "    lstm_dataloader = DataLoader(lstm_dataset, batch_size=lstm_batch_size, shuffle=True)\n",
    "\n",
    "    lstm_model = LSTMVolModel(input_size=2,\n",
    "                              hidden_size=lstm_hidden_size,\n",
    "                              num_layers=lstm_num_layers,\n",
    "                              output_size=1,\n",
    "                              dropout=lstm_dropout).to(device)\n",
    "\n",
    "    lstm_model = train_lstm(lstm_model, lstm_dataloader, lstm_epochs, lstm_lr, device, verbose=False) # Less verbose during tuning\n",
    "\n",
    "    # 2. Estimate Initial GARCH Parameters\n",
    "    omega_garch, alpha_garch, beta_garch = None, None, None\n",
    "    last_h_garch, last_resid_garch = None, None\n",
    "    try:\n",
    "        train_log_returns = train_df['SPX_LogRet'].dropna()\n",
    "        if len(train_log_returns) < max(garch_p, garch_q) + 1: # Need enough points to fit\n",
    "            print(\"Error: Not enough non-NaN log returns in training data to fit GARCH. Skipping.\")\n",
    "            return None\n",
    "\n",
    "        # Ensure variance is not zero before scaling\n",
    "        if train_log_returns.var() < 1e-12:\n",
    "             print(\"Warning: Training log returns have near-zero variance. GARCH might fail. Setting defaults.\")\n",
    "             # Use some default stable params or skip\n",
    "             omega_garch, alpha_garch, beta_garch = 0.01, 0.1, 0.85 # Example defaults\n",
    "             last_resid_garch = 0.0\n",
    "             last_h_garch = train_log_returns.var() if train_log_returns.var() > 1e-12 else 1e-8 # Default variance\n",
    "        else:\n",
    "            garch_model_spec = arch_model(train_log_returns * 100, vol='Garch', p=garch_p, q=garch_q,\n",
    "                                          mean='Zero', dist='Normal') # Keep scaling by 100\n",
    "            res_garch_initial = garch_model_spec.fit(disp='off', show_warning=False)\n",
    "\n",
    "            # Check convergence before accessing parameters\n",
    "            if not res_garch_initial.convergence_flag == 0:\n",
    "                print(f\"Warning: Initial GARCH ({garch_p},{garch_q}) did not converge. Results might be unreliable.\")\n",
    "                # Optionally provide default parameters or skip\n",
    "                # return None # Or use defaults like above\n",
    "\n",
    "            # Extract parameters needed for rolling forecast\n",
    "            params_dict = res_garch_initial.params.to_dict()\n",
    "            omega_garch = params_dict.get('omega', 0.01) # Use defaults if param missing\n",
    "            alpha_garch = params_dict.get(f'alpha[{garch_p}]', 0.1) if garch_p > 0 else 0.0\n",
    "            beta_garch = params_dict.get(f'beta[{garch_q}]', 0.85) if garch_q > 0 else 0.0\n",
    "\n",
    "            # Get last variance and residual (unscale variance)\n",
    "            last_h_garch = res_garch_initial.conditional_volatility[-1]**2 / (100**2)\n",
    "            last_resid_garch = train_log_returns.iloc[-1]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Initial GARCH ({garch_p},{garch_q}) fitting failed: {e}. Skipping experiment.\")\n",
    "        return None # Skip experiment if GARCH fails\n",
    "\n",
    "    # --- Rolling Forecast ---\n",
    "    predictions = {\n",
    "        'Date': [], 'Actual': [], 'GARCH': [], 'LSTM': [], 'Combined_LSTM_GARCH': []\n",
    "    }\n",
    "    lstm_model.eval()\n",
    "\n",
    "    # Iterate through the test set for rolling predictions\n",
    "    # Need length `lstm_seq_len` before the first test point for the first LSTM input\n",
    "    for i in range(len(test_indices) - 1):\n",
    "        t_index = n_train + i # Index in the original df corresponding to time 't'\n",
    "        current_date = df.index[t_index]\n",
    "        next_date = df.index[t_index + 1] # Date for which volatility is being predicted (t+1)\n",
    "\n",
    "        # Ensure we have enough history for LSTM input sequence\n",
    "        start_idx_lstm = t_index - lstm_seq_len\n",
    "        if start_idx_lstm < 0:\n",
    "            # This condition shouldn't be hit if train/test split logic is correct, but as a safeguard:\n",
    "            print(f\"Warning: Skipping prediction for {next_date}, not enough history (t_index={t_index}, seq_len={lstm_seq_len})\")\n",
    "            continue\n",
    "\n",
    "        # 1. Prepare Input Data for step t\n",
    "        input_data_logret_scaled = scaled_df['SPX_LogRet_Scaled'].iloc[start_idx_lstm:t_index].values\n",
    "        input_data_vix_scaled = scaled_df['VIX_Level_Scaled'].iloc[start_idx_lstm:t_index].values\n",
    "\n",
    "        # Ensure shapes are correct before stacking\n",
    "        if len(input_data_logret_scaled) != lstm_seq_len or len(input_data_vix_scaled) != lstm_seq_len:\n",
    "             print(f\"Warning: Incorrect sequence length at index {t_index} ({len(input_data_logret_scaled)} vs {lstm_seq_len}). Skipping.\")\n",
    "             continue\n",
    "\n",
    "\n",
    "        # Actual log return at time t needed for GARCH update\n",
    "        actual_log_ret_t = scaled_df['SPX_LogRet'].iloc[t_index] # Use the unscaled return for GARCH logic\n",
    "\n",
    "        # Create LSTM input tensor (shape: [1, seq_len, num_features])\n",
    "        x_input_np = np.stack((input_data_logret_scaled, input_data_vix_scaled), axis=1).reshape(1, lstm_seq_len, 2)\n",
    "        x_input = torch.tensor(x_input_np, dtype=torch.float32).to(device)\n",
    "\n",
    "        # 2. Get Prediction from LSTM Model (Predicts Volatility sigma_hat_{t+1})\n",
    "        with torch.no_grad():\n",
    "            vol_hat_lstm_tplus1 = lstm_model(x_input).cpu().numpy().flatten()[0]\n",
    "            vol_hat_lstm_tplus1 = max(vol_hat_lstm_tplus1, 0) # Ensure non-negative\n",
    "\n",
    "        # 3. Calculate GARCH Volatility for t+1\n",
    "        epsilon_t_garch = actual_log_ret_t # Innovation at time t\n",
    "\n",
    "        # Calculate variance for day t+1: h_{t+1} = omega + alpha * epsilon_t^2 + beta * h_t\n",
    "        # Use last_resid_garch (logret_{t-1}) and last_h_garch (h_{t-1}) for GARCH(1,1)\n",
    "        # For GARCH(p,q), this update step needs generalization or stick to (1,1) for simplicity here\n",
    "        if garch_p == 1 and garch_q == 1:\n",
    "             # h_t = omega_unscaled + alpha_garch * (last_resid_garch**2) + beta_garch * last_h_garch # variance at t\n",
    "             h_tplus1_garch = omega_garch / (100**2) + alpha_garch * (epsilon_t_garch**2) + beta_garch * last_h_garch\n",
    "        else:\n",
    "             # Fallback or more complex GARCH update needed for p,q > 1 in rolling forecast\n",
    "             # For simplicity, let's just reuse the last prediction if p,q != 1 (or implement the full update logic)\n",
    "             # Re-fitting GARCH daily is too slow for tuning, so we use the formula based on initial params.\n",
    "             # This simulation might be less accurate for GARCH(p,q) != (1,1).\n",
    "             # Let's attempt the GARCH(1,1) formula even if p/q > 1, acknowledging this limitation.\n",
    "             h_tplus1_garch = omega_garch / (100**2) + alpha_garch * (epsilon_t_garch**2) + beta_garch * last_h_garch\n",
    "\n",
    "\n",
    "        h_tplus1_garch = max(h_tplus1_garch, 1e-12) # Prevent sqrt(0) or negative\n",
    "        vol_hat_garch_tplus1 = np.sqrt(h_tplus1_garch) * ANNUALIZATION_FACTOR\n",
    "\n",
    "        # Update GARCH state for next iteration (t becomes t-1 for next step)\n",
    "        # This update is strictly for GARCH(1,1) rolling forecast simulation.\n",
    "        last_h_garch = h_tplus1_garch / (ANNUALIZATION_FACTOR**2) # Update h_t for next step (unannualized variance)\n",
    "        last_resid_garch = epsilon_t_garch # Update epsilon_{t-1} for next step\n",
    "\n",
    "        # 4. Calculate Combined Forecast (Simple Average)\n",
    "        vol_hat_combined_tplus1 = (vol_hat_lstm_tplus1 + vol_hat_garch_tplus1) / 2.0\n",
    "\n",
    "        # 5. Store Predictions and Actuals for day t+1\n",
    "        # Actual realized volatility for day t+1 is stored at index t_index in 'Realized_Vol_Target'\n",
    "        actual_vol_tplus1 = scaled_df['Realized_Vol_Target'].iloc[t_index]\n",
    "\n",
    "        if not pd.isna(actual_vol_tplus1):\n",
    "            predictions['Date'].append(next_date)\n",
    "            predictions['Actual'].append(actual_vol_tplus1)\n",
    "            predictions['GARCH'].append(vol_hat_garch_tplus1)\n",
    "            predictions['LSTM'].append(vol_hat_lstm_tplus1)\n",
    "            predictions['Combined_LSTM_GARCH'].append(vol_hat_combined_tplus1)\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    results_df = pd.DataFrame(predictions)\n",
    "    results_df.set_index('Date', inplace=True)\n",
    "    results_df.dropna(inplace=True) # Drop rows where actual or any prediction is NaN\n",
    "\n",
    "    if results_df.empty:\n",
    "        print(\"No valid results found for evaluation. Skipping.\")\n",
    "        return None # Indicate failure\n",
    "\n",
    "    metrics = {}\n",
    "    for model_name in ['GARCH', 'LSTM', 'Combined_LSTM_GARCH']:\n",
    "        pred = results_df[model_name]\n",
    "        actual = results_df['Actual']\n",
    "        # Check if actual or pred contains NaNs/Infs\n",
    "        if actual.isnull().any() or pred.isnull().any() or np.isinf(actual).any() or np.isinf(pred).any():\n",
    "             print(f\"Warning: NaN or Inf found in actuals or predictions for {model_name}. Skipping metrics calculation.\")\n",
    "             metrics[model_name] = {'MAE': np.nan, 'MSE': np.nan, 'RMSE': np.nan}\n",
    "             continue\n",
    "\n",
    "        # Ensure actual and pred have the same length after potential NaN handling\n",
    "        if len(actual) != len(pred):\n",
    "            print(f\"Warning: Length mismatch between actual ({len(actual)}) and pred ({len(pred)}) for {model_name}. Aligning indices.\")\n",
    "            common_index = actual.index.intersection(pred.index)\n",
    "            actual = actual.loc[common_index]\n",
    "            pred = pred.loc[common_index]\n",
    "\n",
    "        if len(actual) == 0 or len(pred) == 0:\n",
    "            print(f\"Warning: No overlapping data points for {model_name} after alignment. Skipping metrics calculation.\")\n",
    "            metrics[model_name] = {'MAE': np.nan, 'MSE': np.nan, 'RMSE': np.nan}\n",
    "            continue\n",
    "\n",
    "\n",
    "        try:\n",
    "             mae = mean_absolute_error(actual, pred)\n",
    "             mse = mean_squared_error(actual, pred)\n",
    "             rmse = np.sqrt(mse)\n",
    "             metrics[model_name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse}\n",
    "        except Exception as e:\n",
    "             print(f\"Error calculating metrics for {model_name}: {e}. Setting metrics to NaN.\")\n",
    "             metrics[model_name] = {'MAE': np.nan, 'MSE': np.nan, 'RMSE': np.nan}\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Experiment finished. Combined RMSE: {metrics.get('Combined_LSTM_GARCH', {}).get('RMSE', np.nan):.6f}\")\n",
    "    return {\n",
    "        'GARCH_MAE': metrics.get('GARCH', {}).get('MAE', np.nan),\n",
    "        'GARCH_MSE': metrics.get('GARCH', {}).get('MSE', np.nan),\n",
    "        'GARCH_RMSE': metrics.get('GARCH', {}).get('RMSE', np.nan),\n",
    "        'LSTM_MAE': metrics.get('LSTM', {}).get('MAE', np.nan),\n",
    "        'LSTM_MSE': metrics.get('LSTM', {}).get('MSE', np.nan),\n",
    "        'LSTM_RMSE': metrics.get('LSTM', {}).get('RMSE', np.nan),\n",
    "        'Combined_MAE': metrics.get('Combined_LSTM_GARCH', {}).get('MAE', np.nan),\n",
    "        'Combined_MSE': metrics.get('Combined_LSTM_GARCH', {}).get('MSE', np.nan),\n",
    "        'Combined_RMSE': metrics.get('Combined_LSTM_GARCH', {}).get('RMSE', np.nan),\n",
    "    }\n",
    "\n",
    "\n",
    "# --- Hyperparameter Grid ---\n",
    "param_grid = {\n",
    "    'LSTM_INPUT_SEQ_LEN': [20, 40, 60, 120],\n",
    "    'LSTM_HIDDEN_SIZE': [24, 36, 48, 60],\n",
    "    'LSTM_NUM_LAYERS': [1, 2, 3],\n",
    "    'LSTM_DROPOUT': [0.2, 0.3, 0.4],\n",
    "    'LSTM_EPOCHS': [20, 30, 40],\n",
    "    'LSTM_BATCH_SIZE': [8, 16],\n",
    "    'LSTM_LEARNING_RATE': [0.001], # Fixed for now, can add scheduler/tuning later\n",
    "    'GARCH_P': [1, 2],\n",
    "    'GARCH_Q': [1, 2]\n",
    "}\n",
    "\n",
    "# Generate all combinations\n",
    "keys, values = zip(*param_grid.items())\n",
    "param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "print(f\"Total hyperparameter combinations to test: {len(param_combinations)}\")\n",
    "\n",
    "# --- Run Tuning Loop ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "results_list = []\n",
    "# Limit the number of combinations for a quicker test run (optional)\n",
    "# max_combinations = 50\n",
    "# param_combinations = param_combinations[:max_combinations]\n",
    "# print(f\"Testing the first {max_combinations} combinations...\")\n",
    "\n",
    "\n",
    "for params in tqdm(param_combinations, desc=\"Hyperparameter Tuning\"):\n",
    "    # Set seed before each run for consistency within the run\n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "    # Run the experiment for the current set of parameters\n",
    "    result_metrics = run_experiment(params, df_full, device)\n",
    "\n",
    "    # Store results if experiment was successful\n",
    "    if result_metrics is not None:\n",
    "        # Combine params and metrics into one dictionary\n",
    "        current_result = params.copy()\n",
    "        current_result.update(result_metrics)\n",
    "        results_list.append(current_result)\n",
    "    else:\n",
    "        # Store parameters even if the run failed, with NaN metrics\n",
    "        current_result = params.copy()\n",
    "        current_result.update({\n",
    "            'GARCH_MAE': np.nan, 'GARCH_MSE': np.nan, 'GARCH_RMSE': np.nan,\n",
    "            'LSTM_MAE': np.nan, 'LSTM_MSE': np.nan, 'LSTM_RMSE': np.nan,\n",
    "            'Combined_MAE': np.nan, 'Combined_MSE': np.nan, 'Combined_RMSE': np.nan,\n",
    "        })\n",
    "        results_list.append(current_result)\n",
    "\n",
    "\n",
    "# --- Process and Save Results ---\n",
    "results_tuning_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Define the output directory and filename\n",
    "output_dir = './tuning_results'\n",
    "os.makedirs(output_dir, exist_ok=True) # Create directory if it doesn't exist\n",
    "results_filename = os.path.join(output_dir, 'lstm_garch_hyperparameter_tuning_results.csv')\n",
    "\n",
    "# Save the dataframe to CSV\n",
    "results_tuning_df.to_csv(results_filename, index=False)\n",
    "print(f\"\\nHyperparameter tuning results saved to: {results_filename}\")\n",
    "\n",
    "# Display best results based on Combined RMSE\n",
    "results_tuning_df.sort_values(by='Combined_RMSE', inplace=True)\n",
    "print(\"\\nTop 5 Results (Sorted by Combined RMSE):\")\n",
    "print(results_tuning_df.head())\n",
    "\n",
    "# --- Plotting for Comparison ---\n",
    "print(\"\\nGenerating comparison plots...\")\n",
    "\n",
    "# Select a few key hyperparameters to plot against Combined RMSE\n",
    "params_to_plot = ['LSTM_INPUT_SEQ_LEN', 'LSTM_HIDDEN_SIZE', 'LSTM_NUM_LAYERS', 'LSTM_DROPOUT', 'LSTM_EPOCHS', 'LSTM_BATCH_SIZE', 'GARCH_P', 'GARCH_Q']\n",
    "metric_to_plot = 'Combined_RMSE'\n",
    "\n",
    "# Create subplots\n",
    "n_params = len(params_to_plot)\n",
    "n_cols = 3 # Adjust layout as needed\n",
    "n_rows = math.ceil(n_params / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 5, n_rows * 4))\n",
    "axes = axes.flatten() # Flatten to easily iterate\n",
    "\n",
    "for i, param in enumerate(params_to_plot):\n",
    "    ax = axes[i]\n",
    "    # Use seaborn's boxplot for a good overview of distribution\n",
    "    try:\n",
    "        import seaborn as sns\n",
    "        # Check if data exists for the parameter\n",
    "        if param in results_tuning_df.columns and not results_tuning_df[param].isnull().all() and not results_tuning_df[metric_to_plot].isnull().all():\n",
    "             # Convert categorical params to string for better plotting if needed\n",
    "             if results_tuning_df[param].dtype == 'object' or results_tuning_df[param].nunique() < 10:\n",
    "                  plot_data = results_tuning_df.dropna(subset=[metric_to_plot])\n",
    "                  sns.boxplot(x=plot_data[param].astype(str), y=plot_data[metric_to_plot], ax=ax)\n",
    "             else: # For continuous params, maybe a scatter or line plot (boxplot still works)\n",
    "                  plot_data = results_tuning_df.dropna(subset=[metric_to_plot])\n",
    "                  sns.boxplot(x=plot_data[param], y=plot_data[metric_to_plot], ax=ax)\n",
    "\n",
    "             ax.set_title(f'{metric_to_plot} vs {param}')\n",
    "             ax.set_xlabel(param)\n",
    "             ax.set_ylabel(metric_to_plot)\n",
    "             ax.tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "             ax.set_title(f'No data for {param}')\n",
    "             ax.axis('off')\n",
    "\n",
    "    except ImportError:\n",
    "        # Fallback to basic matplotlib scatter if seaborn is not available\n",
    "        if param in results_tuning_df.columns and not results_tuning_df[param].isnull().all() and not results_tuning_df[metric_to_plot].isnull().all():\n",
    "             ax.scatter(results_tuning_df[param], results_tuning_df[metric_to_plot], alpha=0.5)\n",
    "             ax.set_title(f'{metric_to_plot} vs {param}')\n",
    "             ax.set_xlabel(param)\n",
    "             ax.set_ylabel(metric_to_plot)\n",
    "        else:\n",
    "             ax.set_title(f'No data for {param}')\n",
    "             ax.axis('off')\n",
    "\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_filename = os.path.join(output_dir, 'hyperparameter_comparison_plots.png')\n",
    "plt.savefig(plot_filename)\n",
    "print(f\"Comparison plots saved to: {plot_filename}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOOLEFEWiXeXZaaR+a5+F1y",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08535dbdd9d64d1bab97599c0392567d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca4408cfdcae4ee5960adc2e4e68b692",
      "placeholder": "​",
      "style": "IPY_MODEL_64f4fd2a14f445beaccdc095f922ea1c",
      "value": " 0/3456 [00:33&lt;?, ?it/s]"
     }
    },
    "1eb7c8f655894d02903c2ff746513c4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce98cd7d42cb49de9f0d27a9d9b5aef4",
      "max": 3456,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_974efcb13c9349b0a29b55bfde324dfc",
      "value": 0
     }
    },
    "64f4fd2a14f445beaccdc095f922ea1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7035e60f99bc42369329bca22af774c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74c2f36ea580455986ec43b3fe45b357": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "974efcb13c9349b0a29b55bfde324dfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b515561205bc4a2cbf79703fc7f78e8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d886bf4ea00f49a7a21fc9803ba90105",
       "IPY_MODEL_1eb7c8f655894d02903c2ff746513c4c",
       "IPY_MODEL_08535dbdd9d64d1bab97599c0392567d"
      ],
      "layout": "IPY_MODEL_b7502e8e9063469f87b7992a4adffa31"
     }
    },
    "b7502e8e9063469f87b7992a4adffa31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca4408cfdcae4ee5960adc2e4e68b692": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce98cd7d42cb49de9f0d27a9d9b5aef4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d886bf4ea00f49a7a21fc9803ba90105": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7035e60f99bc42369329bca22af774c0",
      "placeholder": "​",
      "style": "IPY_MODEL_74c2f36ea580455986ec43b3fe45b357",
      "value": "Hyperparameter Tuning:   0%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
